Why CUDA C? For the CUDA part, I really like the intricacies of working on the GPU, getting in to that lower level programming where I'm interfacing with the processors. For the C part: I'm a better C programmer than C++ programmer. I'd also say that going along the same lines as to why CUDA, the intricacies, so to is that the case for C. There are a good number of tutorials on how to put together neural net frameworks in C++ and eventually alot of the lower level memory management and orchestration between DRAM, RAM, GPU and CPU gets abstracted away, and it's those very things that make CUDA so fun to begin with! Particularly the question of how to manage memory, ie to minimize latency it becomes necessary to keep data, if possible, in DRAM between operations and minimize mem copies from DRAM->RAM and vice versa which I feel like in many ways is the essence of all of this.

I'd also say the architecture is one of the things that makes all of this so interesting. I'm not a Scala programmer, and my Functional Programming abilities are basic at best. That being said I know enough Functional Programming to understand why Functional Programming pairs so well with parallel programming. If all variables are immutable than race conditions are impossible. CUDA is funnily enough in many ways the antithesis to this, we use lots of pointers, lots of mutable variables, such as p-values in Matrix Multiplication and lots of functions which return void. Martin Odersky would not approve. But it works. 

The aim of this is to a simple feedforward neural network, the number of layers and neurons per layer can be set as args,
then the number of iterations, learning rate and all of that are adjustable hyperparameters in nn.c. Eventually the idea is also to add Convolutional Layers, but first thing is first.
